{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from catboost import CatBoostClassifier\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from category_encoders import TargetEncoder\n",
    "from tpot import TPOTRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Code Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('data/merged.csv', infer_datetime_format=True, low_memory = False)\n",
    "\n",
    "# Drop columns with many unique options\n",
    "data = data.drop(columns = ['Unnamed: 0', 'Non Use Code', 'Assessor Remarks', 'Location', 'OPM remarks'])\n",
    "\n",
    "# Separate numerical and categorical features\n",
    "numerical_features = data.select_dtypes(include=['number']).columns\n",
    "categorical_features = data.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# Impute missing values for numerical features\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data[numerical_features] = imputer.fit_transform(data[numerical_features])\n",
    "\n",
    "# Impute missing values for categorical features\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "data[categorical_features] = imputer.fit_transform(data[categorical_features])\n",
    "\n",
    "# Encode high-cardinality categorical variables using target encoding\n",
    "encoder = TargetEncoder(cols=['Town', 'Address', 'Property Type', 'Residential Type'])\n",
    "data[categorical_features] = encoder.fit_transform(data[categorical_features], data['Sale Amount'])\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop(columns='Sale Amount')  # Features\n",
    "y = data['Sale Amount']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Decision Tree:\n",
      "Validation R-squared for Decision Tree: 0.8317227898498738\n",
      "Test R-squared for Decision Tree: 0.5301348800153661\n",
      "\n",
      "Testing Linear Regression:\n",
      "Validation R-squared for Linear Regression: 0.8018991851684967\n",
      "Test R-squared for Linear Regression: 0.9088160156684683\n",
      "\n",
      "Testing Lasso Regression:\n",
      "Validation R-squared for Lasso Regression: 0.8018996470271533\n",
      "Test R-squared for Lasso Regression: 0.908816241513524\n",
      "\n",
      "Testing Random Forest:\n",
      "Validation R-squared for Random Forest: 0.8614361485901804\n",
      "Test R-squared for Random Forest: 0.9760606769597313\n",
      "\n",
      "Testing XGBoost:\n",
      "Validation R-squared for XGBoost: 0.540781935969054\n",
      "Test R-squared for XGBoost: 0.8528391505438797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Define models to test\n",
    "models = {\n",
    "    # 'CatBoost Regression': CatBoostRegressor(loss_function=\"Poisson\", iterations=400, border_count=254, random_state=25, depth=8),\n",
    "    'Decision Tree': DecisionTreeRegressor(max_depth=6, min_samples_leaf=17, min_samples_split=5),\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Testing {model_name}:\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_val_hat = model.predict(X_val)\n",
    "    validation_score = r2_score(y_val, y_val_hat)\n",
    "    print(f\"Validation R-squared for {model_name}: {validation_score}\")\n",
    "    y_test_hat = model.predict(X_test)\n",
    "    test_score = r2_score(y_test, y_test_hat)\n",
    "    print(f\"Test R-squared for {model_name}: {test_score}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c544b3758ce145749c62516aea6652d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/30 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -35044483261677.93\n",
      "\n",
      "Generation 2 - Current best internal CV score: -35044483261677.93\n",
      "\n",
      "Best pipeline: DecisionTreeRegressor(input_matrix, max_depth=6, min_samples_leaf=17, min_samples_split=5)\n",
      "Test R-squared: -1325454356399.405\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'export'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30531/2651060876.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Get the best pipeline and export it as a Python script (if desired)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mbest_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtpot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitted_pipeline_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mbest_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_regression_pipeline.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'export'"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and run TPOTRegressor for automated model selection with cross-validation\n",
    "tpot = TPOTRegressor(generations=2, population_size=50, random_state=42, n_jobs=-1, verbosity = 2, cv = 5)\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best pipeline on the test set\n",
    "test_score = tpot.score(X_test, y_test)\n",
    "print(\"Test R-squared:\", test_score)\n",
    "\n",
    "# Get the best pipeline and export it as a Python script (if desired)\n",
    "best_pipeline = tpot.fitted_pipeline_\n",
    "best_pipeline.export('best_regression_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "data = pd.read_csv('data/merged.csv', infer_datetime_format=True)\n",
    "\n",
    "# Feature Selection Testing\n",
    "data_full = data.drop(columns= 'Unnamed: 0')\n",
    "data_pruned = data.drop(columns= ['Unnamed: 0', 'Non Use Code', 'Assessor Remarks', 'Location', 'OPM remarks', 'Town', 'Address'])\n",
    "data_max_prune = data.drop(columns= ['Unnamed: 0', 'Non Use Code', 'Assessor Remarks', 'Location', 'Property Type', 'Residential Type', 'OPM remarks'])\n",
    "\n",
    "# Removing Null Values From Data (Could Look Into Mean/Median/Mode Replacement)\n",
    "data_dropped = data_full.dropna()\n",
    "data_pruned_dropped = data_pruned.dropna()\n",
    "data_max_prune_dropped = data_max_prune.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Feature Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Full Data')\n",
    "print(data_full.dtypes, '\\n')\n",
    "\n",
    "print('Data Pruned')\n",
    "print(data_dropped.dtypes, '\\n')\n",
    "\n",
    "print('Data Pruned NA-Dropped')\n",
    "print(data_pruned_dropped.dtypes, '\\n')\n",
    "\n",
    "print('Data Max Prune NA-Dropped')\n",
    "print(data_max_prune_dropped.dtypes, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Feature Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Full Data')\n",
    "print(data_full.count(), '\\n')\n",
    "\n",
    "print('Data Pruned')\n",
    "print(data_dropped.count(), '\\n')\n",
    "\n",
    "print('Data Pruned NA-Dropped')\n",
    "print(data_pruned_dropped.count(), '\\n')\n",
    "\n",
    "print('Data Max Prune NA-Dropped')\n",
    "print(data_max_prune_dropped.count(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix For Feature Selection Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = data_pruned.corr(numeric_only=True)\n",
    "plt.figure(figsize=(12,12))\n",
    "ax = sns.heatmap(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = data_pruned_dropped.corr(numeric_only=True)\n",
    "plt.figure(figsize=(12,12))\n",
    "ax = sns.heatmap(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = data_max_prune_dropped.corr(numeric_only=True)\n",
    "plt.figure(figsize=(12,12))\n",
    "ax = sns.heatmap(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()\n",
    "\n",
    "# # Validation Prediction\n",
    "# y_val_hat = clf.predict(X_val)\n",
    "# validation_score = r2_score(y_val, y_val_hat)\n",
    "# print(\"Validation R-squared:\", validation_score)\n",
    "\n",
    "# # Evaluate the final model's performance on the test set\n",
    "# y_test_hat = clf.predict(X_test)\n",
    "# test_score = r2_score(y_test, y_test_hat)\n",
    "# print(\"Test R-squared:\", test_score)\n",
    "\n",
    "\n",
    "# Handle missing values (you can use other strategies)\n",
    "# data = data.dropna()\n",
    "\n",
    "#One-Hot Encoding Categorical Values With Managable Number of Unique Option (Possibility)\n",
    "#data = pd.get_dummies(data, columns = ['Property Type', 'Residential Type'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
